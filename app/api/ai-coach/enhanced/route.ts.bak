
import { NextRequest, NextResponse } from 'next/server'
import { getServerSession } from 'next-auth'
import { authOptions } from '@/lib/auth'
import { prisma } from '@/lib/db'

export const dynamic = 'force-dynamic'
export const runtime = 'nodejs'

// System prompt builder with full personalization
function buildSystemPrompt(userData: any, recentHistory: any[]) {
  const profile = `
You are Coach Kai, an elite professional pickleball coach specializing in personalized training.

PLAYER PROFILE:
- Name: ${userData.firstName || 'Player'}
- Skill Level: ${userData.skillLevel || 'Intermediate'}
- DUPR Rating: ${userData.duprRating || 'Not set'}
- Primary Goals: ${userData.goals?.map((g: any) => g.title).join(', ') || 'Improve overall game'}
- Membership: ${userData.subscriptionTier || 'Free'} tier

RECENT ACTIVITY:
${userData.recentActivity || 'New user - no activity yet'}

KNOWN STRENGTHS:
${userData.strengths || 'To be assessed'}

AREAS FOR IMPROVEMENT:
${userData.weaknesses || 'To be assessed'}

TRAINING HISTORY:
- Total sessions completed: ${userData.sessionsCompleted || 0}
- Drills completed this month: ${userData.drillsThisMonth || 0}
- Match record (last 30 days): ${userData.matchRecord || 'No matches recorded'}

RECENT CONVERSATION CONTEXT:
${recentHistory.length > 0 ? recentHistory.map(h => `${h.role === 'user' ? 'Player' : 'Coach'}: ${h.content}`).join('\n') : 'First conversation'}

COACHING GUIDELINES:
1. Be encouraging, supportive, and professional
2. Reference their specific goals and recent progress
3. Provide actionable, specific advice (not generic tips)
4. When appropriate, recommend booking a human coach for specialized help
5. Suggest specific drills from the training library when relevant
6. Track patterns in their questions to identify focus areas
7. Celebrate wins and improvements
8. Be honest about areas needing work, but frame constructively
9. Use pickleball terminology appropriately for their skill level
10. Recommend partners/coaches when specialized expertise is needed

Remember: You have access to their complete training history, goals, and performance data. Use this to make responses deeply personal and relevant.
`
  return profile.trim()
}

export async function POST(request: NextRequest) {
  try {
    const session = await getServerSession(authOptions)
    
    if (!session?.user?.email) {
      return NextResponse.json(
        { error: 'Unauthorized' },
        { status: 401 }
      )
    }

    const { message, conversationId } = await request.json()

    if (!message) {
      return NextResponse.json(
        { error: 'Message is required' },
        { status: 400 }
      )
    }

    // Get user with full context
    const user = await prisma.user.findUnique({
      where: { email: session.user.email },
      include: {
        goals: {
          where: { status: 'active' },
          take: 5,
          orderBy: { createdAt: 'desc' }
        },
        achievements: {
          take: 5,
          orderBy: { unlockedAt: 'desc' }
        }
      }
    })

    if (!user) {
      return NextResponse.json(
        { error: 'User not found' },
        { status: 404 }
      )
    }

    // Get or create conversation
    let conversation
    if (conversationId) {
      conversation = await prisma.aiConversation.findUnique({
        where: { id: conversationId },
        include: {
          messages: {
            orderBy: { createdAt: 'desc' },
            take: 10
          }
        }
      })
    } else {
      conversation = await prisma.aiConversation.create({
        data: {
          userId: user.id,
          title: message.substring(0, 50) + (message.length > 50 ? '...' : ''),
          messages: {
            create: {
              role: 'user',
              content: message,
              userId: user.id
            }
          }
        },
        include: {
          messages: {
            orderBy: { createdAt: 'desc' },
            take: 10
          }
        }
      })
    }

    // If existing conversation, add user message
    if (conversationId) {
      await prisma.aiMessage.create({
        data: {
          conversationId: conversation.id,
          userId: user.id,
          role: 'user',
          content: message
        }
      })
    }

    // Build user context for AI
    const userData = {
      firstName: user.firstName,
      skillLevel: user.skillLevel || 'Intermediate',
      duprRating: user.duprRating,
      subscriptionTier: user.subscriptionTier || 'free',
      goals: user.goals,
      achievements: user.achievements,
      sessionsCompleted: user.completedSessions || 0,
      drillsThisMonth: 0, // TODO: Calculate from training data
      matchRecord: 'To be tracked', // TODO: Get from match history
      recentActivity: `Last active: ${new Date().toLocaleDateString()}`,
      strengths: user.strengths || 'To be assessed through training',
      weaknesses: user.weaknesses || 'To be assessed through training'
    }

    // Get recent conversation history (reversed for chronological order)
    const recentHistory = conversation.messages
      .reverse()
      .map(m => ({
        role: m.role,
        content: m.content
      }))

    // Build system prompt with full context
    const systemPrompt = buildSystemPrompt(userData, recentHistory.slice(-10))

    // Prepare messages for AI
    const messages = [
      { role: 'system', content: systemPrompt },
      ...recentHistory.slice(-10),
      { role: 'user', content: message }
    ]

    // Call Abacus.AI LLM API with streaming
    const response = await fetch('https://apps.abacus.ai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.ABACUSAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-4.1-mini',
        messages: messages,
        stream: true,
        max_tokens: 1500,
        temperature: 0.7
      }),
    })

    if (!response.ok) {
      throw new Error(`LLM API error: ${response.statusText}`)
    }

    // Create streaming response
    let fullResponse = ''
    const stream = new ReadableStream({
      async start(controller) {
        const reader = response.body?.getReader()
        const decoder = new TextDecoder()
        const encoder = new TextEncoder()
        
        try {
          while (true) {
            const { done, value } = await reader!.read()
            if (done) {
              // Save assistant message to database
              await prisma.aiMessage.create({
                data: {
                  conversationId: conversation.id,
                  userId: user.id,
                  role: 'assistant',
                  content: fullResponse
                }
              })

              // Update conversation
              await prisma.aiConversation.update({
                where: { id: conversation.id },
                data: {
                  updatedAt: new Date(),
                  messageCount: { increment: 2 } // user + assistant
                }
              })

              break
            }
            
            const chunk = decoder.decode(value)
            
            // Extract content from SSE format
            const lines = chunk.split('\n')
            for (const line of lines) {
              if (line.startsWith('data: ')) {
                const data = line.slice(6)
                if (data === '[DONE]') continue
                
                try {
                  const parsed = JSON.parse(data)
                  const content = parsed.choices?.[0]?.delta?.content || ''
                  if (content) {
                    fullResponse += content
                  }
                } catch (e) {
                  // Skip invalid JSON
                }
              }
            }
            
            controller.enqueue(encoder.encode(chunk))
          }
        } catch (error) {
          console.error('Stream error:', error)
          controller.error(error)
        } finally {
          controller.close()
        }
      },
    })

    return new Response(stream, {
      headers: {
        'Content-Type': 'text/plain; charset=utf-8',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
        'X-Conversation-Id': conversation.id
      },
    })

  } catch (error) {
    console.error('AI Coach API Error:', error)
    return NextResponse.json(
      { error: 'Failed to process request', details: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    )
  }
}

// Get user's conversation history
export async function GET(request: NextRequest) {
  try {
    const session = await getServerSession(authOptions)
    
    if (!session?.user?.email) {
      return NextResponse.json(
        { error: 'Unauthorized' },
        { status: 401 }
      )
    }

    const user = await prisma.user.findUnique({
      where: { email: session.user.email }
    })

    if (!user) {
      return NextResponse.json(
        { error: 'User not found' },
        { status: 404 }
      )
    }

    // Get all conversations for user
    const conversations = await prisma.aiConversation.findMany({
      where: { userId: user.id },
      include: {
        messages: {
          orderBy: { createdAt: 'asc' }
        }
      },
      orderBy: { updatedAt: 'desc' }
    })

    // Calculate usage stats
    const totalMessages = conversations.reduce((sum, conv) => sum + conv.messageCount, 0)
    const totalConversations = conversations.length

    return NextResponse.json({
      conversations,
      stats: {
        totalConversations,
        totalMessages,
        averageMessagesPerConversation: totalConversations > 0 ? Math.round(totalMessages / totalConversations) : 0
      }
    })

  } catch (error) {
    console.error('Get conversations error:', error)
    return NextResponse.json(
      { error: 'Failed to fetch conversations' },
      { status: 500 }
    )
  }
}
